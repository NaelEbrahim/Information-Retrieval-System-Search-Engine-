
# Information Retrieval System

## ğŸ“– Overview

This project is a sophisticated Information Retrieval (IR) system designed to serve as a practical and educational tool for students and instructors in software engineering and computer science. It provides a hands-on implementation of a search engine, complete with a web-based user interface, multiple retrieval models, and evaluation components. The system is built using Python and Flask, with a focus on modularity and extensibility.

## âœ¨ Features

*   **Web-Based UI:** A simple and intuitive web interface built with Flask for searching and viewing documents.
*   **Multiple Retrieval Models:**
    *   **TF-IDF:** A classical vector space model for information retrieval.
    *   **Word2Vec:** A neural network-based model for capturing semantic relationships between words.
    *   **Hybrid Model:** A combination of TF-IDF and Word2Vec scores for improved ranking.
    *   **FAISS-based Search:** A highly efficient similarity search for dense vectors, integrated with the Word2Vec model.
*   **Query Suggestion:** Autocompletes user queries based on the dataset's vocabulary.
*   **Query Expansion:** "Smart" query expansion using Word2Vec to improve search results.
*   **Evaluation Services:** Built-in support for evaluating retrieval performance using standard IR datasets like TREC and ANTIQUE.
*   **Modular Architecture:** The project is structured into services for different functionalities, making it easy to understand, maintain, and extend.

## ğŸ›ï¸ System Architecture

The system is composed of several key components:

*   **`app.py`:** The main Flask application that handles web requests, renders templates, and orchestrates the search process.
*   **`search_engine.py`:** The core of the search functionality, which delegates search requests to the appropriate retrieval model.
*   **Retrieval Models:**
    *   **`tf_idf_singleton_service.py`:** Implements the TF-IDF model, including vectorization and scoring.
    *   **`word2vec_singleton_service.py`:** Implements the Word2Vec model, including document vectorization and scoring.
    *   **`hybrid_search_service.py`:** Combines the results of the TF-IDF and Word2Vec models.
    *   **`vector_store_singleton_service.py`:** Manages the FAISS index for efficient vector similarity search.
*   **`inverted_index_singleton_service.py`:** Manages the inverted index, a core data structure for efficient retrieval.
*   **`document_service_singleton.py`:** Handles loading and accessing document content.
*   **`preprocessor.py`:** Responsible for text preprocessing tasks such as tokenization, stemming, and stopword removal.
*   **Evaluation Services:**
    *   **`TREC_Evaluation_service.py`:** Provides tools for evaluating the system on TREC datasets.
    *   **`ANTIQUE_Evaluation_service.py`:** Provides tools for evaluating the system on the ANTIQUE dataset.
    *   **`Metrics_service.py`:** Calculates standard IR metrics such as Precision, Recall, and Mean Average Precision (MAP).

## Folder Structure

```
.
â”œâ”€â”€ README.md
â”œâ”€â”€ app.py
â”œâ”€â”€ database
â”‚   â”œâ”€â”€ index_files
â”‚   â”‚   â”œâ”€â”€ antique
â”‚   â”‚   â”‚   â”œâ”€â”€ doc_id_to_index.joblib
â”‚   â”‚   â”‚   â”œâ”€â”€ doc_ids.joblib
â”‚   â”‚   â”‚   â”œâ”€â”€ faiss.index
â”‚   â”‚   â”‚   â”œâ”€â”€ inverted_index.joblib
â”‚   â”‚   â”‚   â””â”€â”€ train
â”‚   â”‚   â””â”€â”€ trec
â”‚   â”‚       â”œâ”€â”€ doc_id_to_index.joblib
â”‚   â”‚       â”œâ”€â”€ doc_ids.joblib
â”‚   â”‚       â”œâ”€â”€ faiss.index
â”‚   â”‚       â””â”€â”€ inverted_index.joblib
â”‚   â”œâ”€â”€ tfidf_files
â”‚   â”‚   â”œâ”€â”€ antique
â”‚   â”‚   â”‚   â”œâ”€â”€ tfidf_matrix.joblib
â”‚   â”‚   â”‚   â””â”€â”€ tfidf_vectorizer.joblib
â”‚   â”‚   â””â”€â”€ trec
â”‚   â”‚       â”œâ”€â”€ tfidf_matrix.joblib
â”‚   â”‚       â””â”€â”€ tfidf_vectorizer.joblib
â”‚   â””â”€â”€ word2vec_files
â”‚       â”œâ”€â”€ antique
â”‚       â”‚   â”œâ”€â”€ doc_vectors.joblib
â”‚       â”‚   â””â”€â”€ word2vec.model
â”‚       â””â”€â”€ trec
â”‚           â”œâ”€â”€ doc_vectors.joblib
â”‚           â”œâ”€â”€ word2vec.model
â”‚           â”œâ”€â”€ word2vec.model.syn1neg.npy
â”‚           â””â”€â”€ word2vec.model.wv.vectors.npy
â”œâ”€â”€ model_building_documentation.txt
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ scripts
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ build_index.py
â”‚   â””â”€â”€ load_datasets.py
â”œâ”€â”€ services
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ evaluation
â”‚   â”‚   â”œâ”€â”€ antique_evaluation_service.py
â”‚   â”‚   â”œâ”€â”€ metrics_service.py
â”‚   â”‚   â””â”€â”€ trec_evaluation_service.py
â”‚   â”œâ”€â”€ helpers
â”‚   â”‚   â”œâ”€â”€ query_expander_service.py
â”‚   â”‚   â””â”€â”€ query_suggestion_service.py
â”‚   â”œâ”€â”€ indexing
â”‚   â”‚   â””â”€â”€ inverted_index_singleton_service.py
â”‚   â”œâ”€â”€ modeling
â”‚   â”‚   â”œâ”€â”€ tfidf_service.py
â”‚   â”‚   â””â”€â”€ word2vec_service.py
â”‚   â”œâ”€â”€ nlp
â”‚   â”‚   â”œâ”€â”€ preprocessor.py
â”‚   â”‚   â””â”€â”€ spell_corrector.py
â”‚   â”œâ”€â”€ retrieval
â”‚   â”‚   â”œâ”€â”€ document_service_singleton.py
â”‚   â”‚   â”œâ”€â”€ hybrid_search_service.py
â”‚   â”‚   â”œâ”€â”€ tf_idf_singleton_service.py
â”‚   â”‚   â”œâ”€â”€ vector_store_singleton_service.py
â”‚   â”‚   â””â”€â”€ word2vec_singleton_service.py
â”‚   â””â”€â”€ search
â”‚       â””â”€â”€ search_engine.py
â”œâ”€â”€ static
â”‚   â””â”€â”€ css
â”‚       â””â”€â”€ style.css
â”œâ”€â”€ structure.md
â””â”€â”€ templates
    â”œâ”€â”€ base.html
    â”œâ”€â”€ document.html
    â”œâ”€â”€ index.html
    â”œâ”€â”€ not_found.html
    â””â”€â”€ results.html
```

## ğŸš€ Getting Started

### Prerequisites

*   Python 3.8+
*   Pip for package management

### Installation & Setup

1.  **Clone the repository:**
    ```bash
    git clone <repository-url>
    cd <repository-directory>
    ```

2.  **Install the required packages:**
    ```bash
    pip install -r requirements.txt
    ```

3.  **Build Models and Indices:**
    Before running the application, you must build the necessary models. Please follow the instructions in the **"Building Required Models and Indices"** section below.

4.  **Run the Application:**
    Once the setup is complete, you can run the Flask application:
    ```bash
    python app.py
    ```
    The application will be available at `http://127.0.0.1:5000`.

## ğŸ› ï¸ Building Required Models and Indices

This is a mandatory one-time setup process. Before running the application for the first time, you must build the data models. This involves training the TF-IDF and Word2Vec models and then creating the inverted index.

**Run the following commands from the project's root directory in the exact order shown:**

1.  **Train TF-IDF Models:**
    ```bash
    python -m services.modeling.tfidf_service
    ```

2.  **Train Word2Vec Models:**
    ```bash
    python -m services.modeling.word2vec_service
    ```

3.  **Build the Inverted Index:**
    ```bash
    python -m scripts.build_index
    ```

> **Note:** For a detailed explanation of the model building and loading architecture, please see the `model_building_documentation.txt` file in this repository.

## Usage

### Searching

1.  Open your web browser and navigate to `http://127.0.0.1:5000`.
2.  Enter your search query in the search box.
3.  Select the dataset and retrieval model you want to use.
4.  Click the "Search" button to view the results.

### Evaluation

The evaluation services can be used to measure the performance of the retrieval models. You can run the evaluation scripts from the command line:

```bash
python -m services.evaluation.antique_evaluation_service
python -m services.evaluation.trec_evaluation_service
```

## ğŸ› ï¸ Technologies Used

*   **Python:** The core programming language.
*   **Flask:** A lightweight web framework for the user interface.
*   **Gensim:** For Word2Vec model training and implementation.
*   **Scikit-learn:** For TF-IDF vectorization and cosine similarity calculations.
*   **NLTK:** For natural language processing tasks like tokenization and stopword removal.
*   **FAISS:** A library for efficient similarity search and clustering of dense vectors.
*   **NumPy:** For numerical operations.

## í“¨ Future Work

*   **Integration of more advanced retrieval models:** Such as BERT or other transformer-based models.
*   **User feedback and relevance feedback:** Allow users to provide feedback on search results to improve future rankings.
*   **Distributed indexing and search:** To support larger datasets and higher query loads.
*   **More comprehensive evaluation metrics:** And visualization of evaluation results.
